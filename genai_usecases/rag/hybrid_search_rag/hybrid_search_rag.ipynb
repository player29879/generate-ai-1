{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxxOWz9dpsYj"
      },
      "source": [
        "#\tWhat is Hybrid Search?\n",
        "\n",
        "Hybrid (Ensemble) Search is a technique that combines multiple search methods to improve retrieval performance. Typically, it combines traditional keyword-based search (like BM25) with semantic search (using embedding models). This approach can provide better results than either method alone, especially for queries that have both keyword-specific and semantic aspects.\n",
        "\n",
        "\n",
        "# Hybrid-search RAG Implementation:\n",
        "\n",
        "1. **Hybrid Retrieval:** We use the EnsembleRetriever to get relevant documents using both keyword-based and semantic search.\n",
        "2. **Response Generation:** Using the retrieved context, we generate a final response to the original query.\n",
        "3. **Hybrid Search Explanation:** We generate an explanation of how the hybrid search process might have improved the retrieval of relevant information.\n",
        "\n",
        "# Setup\n",
        "\n",
        "1. **[LLM](https://deepmind.google/technologies/gemini/pro/):** Google's free gemini-pro api endpoint ([Google's API Key](https://console.cloud.google.com/apis/credentials))\n",
        "2. **[Vector Store](https://www.pinecone.io/learn/vector-database/):** [ChromaDB](https://www.trychroma.com/)\n",
        "3. **[Embedding Model](https://qdrant.tech/articles/what-are-embeddings/):** [nomic-embed-text-v1.5](https://www.nomic.ai/blog/posts/nomic-embed-text-v1)\n",
        "4. **[LLM Framework](https://python.langchain.com/v0.2/docs/introduction/):** LangChain\n",
        "5. **[Huggingface API Key](https://huggingface.co/settings/tokens)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3axTI0sp5Hg"
      },
      "source": [
        "# Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShxTNxM5gqtr",
        "outputId": "7fc4861f-5d5c-4ef9-b8af-78d2054d54ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m465.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U \\\n",
        "     Sentence-transformers==3.0.1 \\\n",
        "     langchain==0.2.11 \\\n",
        "     langchain-google-genai==1.0.7 \\\n",
        "     langchain-chroma==0.1.2 \\\n",
        "     langchain-community==0.2.10 \\\n",
        "     langchain-huggingface==0.0.3 \\\n",
        "     einops==0.8.0 \\\n",
        "     rank_bm25==0.2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJ1vqs-p_Zx"
      },
      "source": [
        "# Import related libraries related to Langchain, HuggingfaceEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RL-3LsYogoH5"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import (\n",
        "    ChatGoogleGenerativeAI,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        ")\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GT55z5AkhyOW"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UeDlrgqI2A"
      },
      "source": [
        "# Provide Google API Key. You can create Google API key at following link\n",
        "\n",
        "[Google Gemini-Pro API Creation Link](https://console.cloud.google.com/apis/credentials)\n",
        "\n",
        "[YouTube Video](https://www.youtube.com/watch?v=ZHX7zxvDfoc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobvrD3glfd4",
        "outputId": "9612397f-df85-436e-eb27-da67bb30ac47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1dLpYboqeIK"
      },
      "source": [
        "# Provide Huggingface API Key. You can create Huggingface API key at following lin\n",
        "\n",
        "[Higgingface API Creation Link](https://huggingface.co/settings/tokens)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ6scBGZlhpG",
        "outputId": "7a82bd78-f5c3-4384-be56-7aa4d0333389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"HF_TOKEN\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load and preprocess data"
      ],
      "metadata": {
        "id": "XuQFpTS0m6uk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KB5uBtu9yia2"
      },
      "outputs": [],
      "source": [
        "def load_and_process_data(url):\n",
        "    # Load data from web\n",
        "    loader = WebBaseLoader(url)\n",
        "    data = loader.load()\n",
        "\n",
        "    # Split text into chunks (Experiment with Chunk Size and Chunk Overlap to get optimal chunking)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create vector store and BM25 retriever"
      ],
      "metadata": {
        "id": "XaH9Jt_lnBQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_retrievers(chunks):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"nomic-ai/nomic-embed-text-v1.5\", model_kwargs = {'trust_remote_code': True})\n",
        "    vectorstore = Chroma.from_documents(chunks, embeddings)\n",
        "    bm25_retriever = BM25Retriever.from_documents(chunks)\n",
        "    bm25_retriever.k = 5  # Set number of documents to retrieve\n",
        "\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[bm25_retriever, vectorstore.as_retriever(search_kwargs={\"k\": 5})],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "\n",
        "    return ensemble_retriever"
      ],
      "metadata": {
        "id": "tfS6GRLBnKHZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Hybrid-search RAG related code\n",
        "\n",
        "1. **Hybrid Retrieval:** We use the EnsembleRetriever to get relevant documents using both keyword-based and semantic search.\n",
        "2. **Response Generation:** Using the retrieved context, we generate a final response to the original query.\n",
        "3. **Hybrid Search Explanation:** We generate an explanation of how the hybrid search process might have improved the retrieval of relevant information."
      ],
      "metadata": {
        "id": "fGleoT_JqGwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_search_rag(query, ensemble_retriever, llm):\n",
        "    # Hybrid retrieval\n",
        "    retrieved_docs = ensemble_retriever.invoke(query)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "    # Generate response\n",
        "    response_prompt = ChatPromptTemplate.from_template(\n",
        "        \"You are an AI assistant tasked with answering questions based on the provided context. \"\n",
        "        \"The context contains information retrieved using a hybrid search method combining keyword-based and semantic search. \"\n",
        "        \"Please provide a comprehensive answer to the question, using the context when relevant \"\n",
        "        \"and your general knowledge when necessary.\\n\\n\"\n",
        "        \"Context:\\n{context}\\n\\n\"\n",
        "        \"Question: {query}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    try:\n",
        "        response = llm.invoke(response_prompt.format(context=context, query=query))\n",
        "        final_answer = response.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        final_answer = \"I apologize, but I encountered an error while generating the response.\"\n",
        "\n",
        "    # Generate explanation of hybrid search process\n",
        "    explanation_prompt = ChatPromptTemplate.from_template(\n",
        "        \"Explain how the hybrid search process, combining keyword-based and semantic search, \"\n",
        "        \"might have improved the retrieval of relevant information for answering the given query. \"\n",
        "        \"Consider the potential benefits of this approach compared to using only one search method.\\n\\n\"\n",
        "        \"Query: {query}\\n\"\n",
        "        \"Explanation:\"\n",
        "    )\n",
        "    try:\n",
        "        explanation = llm.invoke(explanation_prompt.format(query=query))\n",
        "        hybrid_search_explanation = explanation.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating explanation: {e}\")\n",
        "        hybrid_search_explanation = \"Unable to generate explanation due to an error.\"\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"final_answer\": final_answer,\n",
        "        \"hybrid_search_explanation\": hybrid_search_explanation,\n",
        "        \"retrieved_context\": context\n",
        "    }"
      ],
      "metadata": {
        "id": "X2D4HfKYpIDI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Create chunk of web data to Chroma Vector Store"
      ],
      "metadata": {
        "id": "8ruDFbkqo07k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the gemini-pro language model with specified settings (Change temeprature  and other parameters as per your requirement)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, safety_settings={\n",
        "          HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        },)\n",
        "\n",
        "# Load and process data\n",
        "url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
        "chunks = load_and_process_data(url)\n",
        "\n",
        "# Create hybrid_results retriever\n",
        "ensemble_retriever  = create_retrievers(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN0Tt1Ago4E5",
        "outputId": "787f8935-14c5-41cf-b6c1-9bcf51eb7011"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.e55a7d4324f65581af5f483e830b80f34680e8ff.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries\n",
        "queries = [\n",
        "        \"What are the main applications of artificial intelligence in healthcare?\"\n",
        "    ]\n",
        "\n",
        "# Run Hybrid-search RAG for each query\n",
        "for query in queries:\n",
        "  print(f\"\\nQuery: {query}\")\n",
        "  result = hybrid_search_rag(query, ensemble_retriever, llm)\n",
        "  print(\"Final Answer:\")\n",
        "  print(result[\"final_answer\"])\n",
        "  print(\"\\nHybrid Search Explanation:\")\n",
        "  print(result[\"hybrid_search_explanation\"])\n",
        "  print(\"\\nRetrieved Context (first 300 characters):\")\n",
        "  print(result[\"retrieved_context\"][:300] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sD3xMXcpBL7",
        "outputId": "d91f559c-af7b-4366-ad7f-f46430fdef64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What are the main applications of artificial intelligence in healthcare?\n",
            "Final Answer:\n",
            "The main applications of artificial intelligence in healthcare include increasing patient care and quality of life. AI can be used to more accurately diagnose and treat patients, as well as to assist with tasks such as medical research and drug discovery.\n",
            "\n",
            "Hybrid Search Explanation:\n",
            "**Hybrid Search Process**\n",
            "\n",
            "The hybrid search process combines keyword-based and semantic search to enhance the retrieval of relevant information.\n",
            "\n",
            "**Keyword-Based Search:**\n",
            "\n",
            "* Identifies documents containing specific keywords from the query.\n",
            "* Provides a broad set of results, including both relevant and irrelevant documents.\n",
            "\n",
            "**Semantic Search:**\n",
            "\n",
            "* Analyzes the meaning and context of the query.\n",
            "* Identifies documents that are semantically related to the query, even if they do not contain exact keywords.\n",
            "\n",
            "**Benefits of Hybrid Search:**\n",
            "\n",
            "**Improved Relevance:**\n",
            "\n",
            "* Semantic search complements keyword-based search by identifying documents that are conceptually relevant to the query, even if they do not contain all the exact keywords.\n",
            "* This reduces the number of irrelevant results and improves the overall accuracy of the search.\n",
            "\n",
            "**Enhanced Contextual Understanding:**\n",
            "\n",
            "* Semantic search provides a deeper understanding of the user's intent by analyzing the context of the query.\n",
            "* It can identify documents that address specific aspects or subtopics of the query, ensuring that the results are more comprehensive and tailored to the user's needs.\n",
            "\n",
            "**Reduced Ambiguity:**\n",
            "\n",
            "* Keyword-based search can be ambiguous, especially for queries with multiple meanings.\n",
            "* Semantic search helps resolve ambiguity by considering the context and relationships between words in the query.\n",
            "\n",
            "**Example for the Query:**\n",
            "\n",
            "**Keyword-Based Search:**\n",
            "\n",
            "* Would retrieve documents containing the keywords \"artificial intelligence\" and \"healthcare.\"\n",
            "* May include irrelevant results about AI in other industries or general healthcare information.\n",
            "\n",
            "**Semantic Search:**\n",
            "\n",
            "* Would identify documents that specifically discuss the applications of AI in healthcare, such as:\n",
            "    * AI-powered medical diagnosis systems\n",
            "    * AI-assisted drug discovery\n",
            "    * AI-enabled personalized treatment plans\n",
            "\n",
            "**Hybrid Search:**\n",
            "\n",
            "* Combines the results from both methods, providing a more comprehensive and relevant set of documents.\n",
            "* Includes documents that contain the exact keywords and those that are semantically related to the query.\n",
            "* Improves the user's ability to find the most relevant information quickly and efficiently.\n",
            "\n",
            "Retrieved Context (first 300 characters):\n",
            "Other industry-specific tasks\n",
            "There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.[157] A few examples are energy stora...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}