{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-v19XlsqP7mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a7374c-a09b-47dd-bde3-01a9d37917cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Code to mount Google Drive at Colab Notebook instance\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Install Langchain and Google Gemini related libraries**"
      ],
      "metadata": {
        "id": "6dNa79_nt5dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain\n",
        "!pip install -q -U google-generativeai langchain-google-genai"
      ],
      "metadata": {
        "id": "r76L6X4AQJEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78ed8db-8b0e-4054-9ab8-bfbf765631f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Get Gemini Key from Secrets **\n",
        "Set GEMINI_KEY secret key at Google Colab and get that here to runn Google Gemini LLM. You can get Google Gemini Key from following link https://makersuite.google.com/app/apikey"
      ],
      "metadata": {
        "id": "VkmAUJVzuG2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_KEY')"
      ],
      "metadata": {
        "id": "FXFDa9vmuCb4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", max_output_tokens=512, temperature=0.0, top_k = 3, top_p=0.2, google_api_key=GOOGLE_API_KEY, convert_system_message_to_human=True)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"Complete the following question with single word only based only on the provided context:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input} \"\"\")\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "context = \"\"\"Tom is a multifaceted individual whose life is a vibrant tapestry woven with threads of learning, adventure, comfort, partying, and creativity. With a profound appreciation for knowledge, Tom approaches each day as an opportunity for intellectual growth and discovery. His insatiable curiosity drives him to explore a myriad of subjects, from philosophy to physics, constantly expanding his understanding of the world around him.\n",
        "\n",
        "Yet, Tom is not content to merely absorb information passively; he seeks out adventure at every turn, craving the thrill of new experiences and the challenge of pushing his boundaries. Whether trekking through dense jungles, scaling towering peaks, or diving into uncharted waters, Tom finds solace and excitement in the great outdoors.\n",
        "\n",
        "Despite his adventurous spirit, Tom also values comfort and relaxation. He revels in quiet moments spent in cozy surroundings, surrounded by familiar comforts and indulging in leisurely pursuits.\n",
        "\n",
        "And when the time comes to celebrate, Tom knows how to throw a party like no other. With his infectious energy and zest for life, he effortlessly brings people together, creating unforgettable memories and moments of joy.\n",
        "\n",
        "But perhaps Tom's most remarkable quality is his boundless creativity. Whether it's through his art, music, or innovative ideas, he constantly pushes the boundaries of imagination, inspiring those around him to think outside the box and embrace their own creativity. With Tom, every day is a journey of learning, adventure, comfort, partying, and endless creativity.\"\"\"\n",
        "\n",
        "document_chain.invoke({\n",
        "    \"input\": \"Tom Loves _\",\n",
        "    \"context\": [Document(page_content=context)]\n",
        "})"
      ],
      "metadata": {
        "id": "b79l68afUlCM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad66b3ea-f41c-4111-b521-0a9224051bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}