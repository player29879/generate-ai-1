{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain==0.2.7 langchain-core==0.2.12 langchain-community==0.2.7 langchain-google-genai==1.0.7 python-dotenv==1.0.1"
      ],
      "metadata": {
        "id": "VzgWoNKpKy_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eda6630-6c50-44b5-9dde-a3323c8057e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.8/355.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import (\n",
        "    ChatGoogleGenerativeAI,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        ")\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "-b3v6AyXQhhB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provide the API key you created or were given."
      ],
      "metadata": {
        "id": "PDVkfK3cNASA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk8CIgKXQr_Z",
        "outputId": "cf52e2ac-ac41-4b96-c487-78b992f48549"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "        Answer the question as detailed as possible.\n",
        "            Question: \\n{question}\\n\n",
        "\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "question = \"\"\"How can AI and machine learning be integrated into\n",
        "    microservices architecture to improve scalability and reliability in telecom systems?\n",
        "    \"\"\"\n",
        "\n",
        "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=api_key, safety_settings={\n",
        "          HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        },)\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[ \"question\"])\n",
        "\n",
        "llm_chain = prompt | llm\n",
        "\n",
        "response = llm_chain.invoke({'question':question})"
      ],
      "metadata": {
        "id": "8acE_AOhQzhK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "lflWQ0BiRWnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356c867b-972b-4506-ee20-a241b3c76e35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Integration of AI and Machine Learning into Microservices Architecture for Enhanced Scalability and Reliability in Telecom Systems**\n",
            "\n",
            "**Introduction**\n",
            "Microservices architecture has emerged as a popular approach for designing and developing complex telecom systems. By decomposing a system into smaller, independent services, microservices architecture offers improved scalability, flexibility, and maintainability. However, as telecom systems grow in size and complexity, managing and optimizing these microservices can become challenging.\n",
            "\n",
            "Artificial intelligence (AI) and machine learning (ML) technologies provide powerful tools for automating tasks, improving decision-making, and optimizing system performance. By integrating AI and ML into microservices architecture, telecom operators can enhance the scalability and reliability of their systems.\n",
            "\n",
            "**Benefits of AI and ML Integration**\n",
            "\n",
            "* **Automated Service Discovery and Management:** AI-powered algorithms can automatically discover and manage microservices, ensuring that they are available and accessible when needed. This reduces the operational overhead and improves the overall efficiency of the system.\n",
            "* **Dynamic Scaling:** ML models can predict traffic patterns and resource utilization, enabling the system to scale up or down dynamically based on demand. This optimizes resource allocation and prevents performance bottlenecks.\n",
            "* **Fault Detection and Recovery:** AI algorithms can monitor microservices for anomalies and failures, and trigger automated recovery mechanisms to minimize downtime and maintain system reliability.\n",
            "* **Performance Optimization:** ML techniques can analyze system metrics and identify performance bottlenecks, allowing operators to optimize the configuration and resource allocation of microservices for improved performance.\n",
            "* **Predictive Maintenance:** AI models can predict the likelihood of microservice failures based on historical data, enabling proactive maintenance and preventing outages.\n",
            "\n",
            "**Integration Approaches**\n",
            "\n",
            "There are several approaches to integrate AI and ML into microservices architecture:\n",
            "\n",
            "* **Centralized AI/ML Platform:** A centralized platform provides a shared pool of AI/ML services that can be accessed by all microservices. This approach simplifies development and maintenance, but may introduce performance bottlenecks.\n",
            "* **Decentralized AI/ML:** Each microservice has its own embedded AI/ML capabilities, enabling autonomous decision-making and optimization. This approach provides greater flexibility and scalability, but requires more development effort.\n",
            "* **Hybrid Approach:** A combination of centralized and decentralized AI/ML, where some services use shared AI/ML platform while others have embedded capabilities. This approach balances flexibility and performance.\n",
            "\n",
            "**Use Cases**\n",
            "\n",
            "* **Network Optimization:** AI/ML algorithms can analyze network traffic patterns and optimize routing, congestion control, and resource allocation to improve network performance and reduce latency.\n",
            "* **Service Assurance:** AI/ML models can monitor service quality metrics, detect anomalies, and trigger corrective actions to ensure service availability and reliability.\n",
            "* **Fraud Detection:** AI/ML algorithms can analyze call patterns, usage data, and other factors to identify fraudulent activities and prevent financial losses.\n",
            "* **Customer Experience Management:** AI/ML can analyze customer interactions, identify pain points, and provide personalized recommendations to improve customer satisfaction.\n",
            "\n",
            "**Conclusion**\n",
            "Integrating AI and ML into microservices architecture offers significant benefits for telecom systems, including improved scalability, reliability, and performance. By automating tasks, optimizing resource allocation, and predicting failures, AI/ML technologies empower telecom operators to deliver high-quality services to their customers while reducing operational costs and downtime.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuzaJ_tGQhGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}